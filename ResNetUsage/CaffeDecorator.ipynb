{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caffe import layers as L, params as P\n",
    "import caffe\n",
    "from pylab import *\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "caffe.set_mode_gpu()\n",
    "caffe.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaffeSolverDecorator:\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        root = 'proto'\n",
    "        self.name = name\n",
    "        self.solver_path = os.path.join(root, self.name, '_solver.prototxt')\n",
    "        self.train_path = os.path.join(root, self.name, '_train.prototxt')\n",
    "        self.test_path = os.path.join(root, self.name, '_test.prototxt')\n",
    "        self.solver = None\n",
    "    \n",
    "    def create_solver_conf(self, optimize_type, lr, need_snapshot=False):\n",
    "        s = caffe.proto.caffe_pb2.SolverParameter()\n",
    "        \n",
    "        s.train_net = self.train_path\n",
    "        \n",
    "        s.test_net.append(self.test_path)\n",
    "        \n",
    "        s.type = optimize_type\n",
    "        s.base_lr = lr\n",
    "        \n",
    "        s.lr_policy = 'inv'\n",
    "        s.gamma = 0.0001\n",
    "        s.weight_decay = 0.0005\n",
    "        \n",
    "        if optimize_type.__eq__('SGD') or optimize_type.__eq__('Adam'):\n",
    "            s.momentum = 0.9\n",
    "            \n",
    "        if optimize_type.__eq__('Adam'):\n",
    "            s.momentum2 = 0.999\n",
    "            s.delta = 10e-8\n",
    "            \n",
    "        if optimize_type.__eq__('RMSProp'):\n",
    "            s.rms_decay = 0.99\n",
    "            \n",
    "        s.solver_mode = caffe.proto.caffe_pb2.SolverParameter.GPU\n",
    "        \n",
    "        with open(self.solver_path, 'w') as f:\n",
    "            f.write(str(s))\n",
    "            \n",
    "        self.solver = caffe.get_solver(self.solver_path)\n",
    "        \n",
    "    def show_net_model(self):\n",
    "        data =  [(k, v.data.shape) for k, v in solver.net.blobs.items()]  \n",
    "        print(data)\n",
    "\n",
    "    def start_solver(solver, epoch=10_000, batch_size=40, test_interval=500, test_iter=100, train_interval=100):\n",
    "        train_loss = zeros(int(epoch / train_interval))\n",
    "        train_acc = zeros(int(epoch / train_interval))\n",
    "        test_acc = zeros(int(epoch / test_interval))\n",
    "        test_loss = zeros(int(epoch / test_interval))\n",
    "\n",
    "\n",
    "        for it in tqdm(range(epoch)):\n",
    "            solver.step(1)\n",
    "\n",
    "            if it % train_interval == 0:\n",
    "                print(f\"###### Iterration #{it}\")\n",
    "                train_loss[it // train_interval] = solver.net.blobs['loss'].data\n",
    "                train_acc[it // train_interval] = solver.net.blobs['accuracy_top1'].data\n",
    "                print(f\"Train net output: accuracy = {train_acc[it // train_interval]}, loss = {train_loss[it // train_interval]}\")\n",
    "\n",
    "            if it % test_interval == 0:\n",
    "                correct = 0\n",
    "                for test_it in range(test_iter):\n",
    "                    solver.test_nets[0].forward()\n",
    "\n",
    "                    correct += sum(solver.test_nets[0].blobs['score'].data.argmax(axis=1)\n",
    "                                   == solver.test_nets[0].blobs['label'].data)\n",
    "\n",
    "                test_acc[it // test_interval] = correct / (test_iter * batch_size)\n",
    "\n",
    "            test_loss[it // test_interval] = solver.test_nets[0].blobs['loss'].data\n",
    "            print(f\"Test net output: accuracy = {test_acc[it // test_interval]}, loss = {test_loss[it // test_interval]}\")\n",
    "                \n",
    "        self.show_plots(\"Train\", train_loss, train_acc, train_interval)\n",
    "        self.show_plots(\"Test\", test_loss, test_acc, test_interval)\n",
    "        return train_loss, train_acc, train_interval, test_loss, test_acc, test_interval\n",
    "    \n",
    "    def show_plots(what_see, test_loss, test_acc, test_interval):\n",
    "        _, ax1 = subplots()\n",
    "        ax2 = ax1.twinx()\n",
    "        ax1.plot(test_interval * arange(len(test_loss)), test_loss)\n",
    "        ax2.plot(test_interval * arange(len(test_acc)), test_acc, 'r')\n",
    "        ax1.set_xlabel('iteration')\n",
    "        ax1.set_ylabel(what_see + ' loss')\n",
    "        ax2.set_ylabel(what_see + ' accuracy')\n",
    "        ax2.set_title(what_see + ' Accuracy: {:.2f}'.format(test_acc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaffeNet:\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.net_train = caffe.NetSpec()\n",
    "        self.net_test = caffe.NetSpec()\n",
    "        self.layers_creator = CaffeLayersCreator()\n",
    "        self.is_created = False\n",
    "        self.net_train_top_layer = None\n",
    "        self.net_test_top_layer = None\n",
    "        \n",
    "        self.conv_counter = 1\n",
    "        self.relu_counter = 1\n",
    "        self.pool_counter = 1\n",
    "        self.batch_counter = 1\n",
    "        self.fc_counter = 1\n",
    "        \n",
    "    # Hidden layers = in_place attr\n",
    "    def set_global_params(self, batch_sizes, weight_params, bias_params, image_params, count_of_classes, hidden_layers=True):\n",
    "        self.train_batch_size = batch_sizes['train']\n",
    "        self.test_batch_size = batch_sizes['test']\n",
    "        self.weight_params = weight_params\n",
    "        self.image_params = image_params\n",
    "        self.count_of_classes = count_of_classes\n",
    "        self.hidden_layers = hidden_layers\n",
    "        \n",
    "        if self.is_created:\n",
    "            print('Call build before you will try start the train (need to update global params)')\n",
    "        \n",
    "    def l_image_data(self, image_params=None):\n",
    "        if image_params is None:\n",
    "            image_params = self.image_params\n",
    "        \n",
    "        train_set = self.image_params['train']\n",
    "        test_set = self.image_params['test']\n",
    "        self.net_train['data'], self.net_train['label'] = self.layers_creator.l_image_data_create(self.train_batch_size, train_set, image_params)\n",
    "        self.net_test['data'], self.net_test['label'] = self.layers_creator.l_image_data_create(self.test_batch_size, test_set, image_params)\n",
    "                \n",
    "        self.net_train_top_layer = self.net_train['data']\n",
    "        self.net_test_top_layer = self.net_test['data']\n",
    "        \n",
    "    def l_conv(self, kernel, filter_count, weight_filter=None, padding=1):\n",
    "        if weight_filter is None:\n",
    "            weight_filter = self.weight_params\n",
    "        layer_name = 'conv' + str(self.conv_counter)\n",
    "        self.net_train[layer_name] = self.layers_creator.l_conv_create(self.net_train_top_layer, kernel, filter_count, weight_filter, padding)\n",
    "        self.net_test[layer_name] = self.layers_creator.l_conv_create(self.net_test_top_layer, kernel, filter_count, weight_filter, padding)\n",
    "        self.conv_counter += 1\n",
    "                \n",
    "        self.net_train_top_layer = self.net_train[layer_name]\n",
    "        self.net_test_top_layer = self.net_test[layer_name]\n",
    "        \n",
    "        \n",
    "    def l_pool(self, kernel_size, stride, pool=P.Pooling.MAX):\n",
    "        layer_name = 'pool' + str(self.pool_counter)\n",
    "        self.net_train[layer_name] = self.layers_creator.l_pool_create(self.net_train_top_layer, kernel_size, stride, pool)\n",
    "        self.net_test[layer_name] = self.layers_creator.l_pool_create(self.net_test_top_layer,  kernel_size, stride, pool)\n",
    "        self.pool_counter += 1\n",
    "        \n",
    "        self.net_train_top_layer = self.net_train[layer_name]\n",
    "        self.net_test_top_layer = self.net_test[layer_name]\n",
    "    \n",
    "    def l_batch(self):\n",
    "        layer_name = 'batch' + str(self.batch_counter)\n",
    "        self.net_train[layer_name] = self.layers_creator.l_batch_create(self.net_train_top_layer)\n",
    "        self.net_test[layer_name] = self.layers_creator.l_batch_create(self.net_test_top_layer)\n",
    "        self.batch_counter += 1\n",
    "        print(self.net_train.to_proto())\n",
    "        print(self.net_test.to_proto())\n",
    "        \n",
    "        self.net_train_top_layer = self.net_train[layer_name]\n",
    "        self.net_test_top_layer = self.net_test[layer_name]\n",
    "        \n",
    "    def l_relu(self, hidden=None):\n",
    "        if hidden is None:\n",
    "            hidden = self.hidden_layers\n",
    "        layer_name = 'relu' + str(self.relu_counter)\n",
    "        self.net_train[layer_name] = self.layers_creator.l_relu_create(self.net_train_top_layer, hidden)\n",
    "        self.net_test[layer_name] = self.layers_creator.l_relu_create(self.net_test_top_layer, hidden)\n",
    "        self.relu_counter += 1\n",
    "        \n",
    "        self.net_train_top_layer = self.net_train[layer_name]\n",
    "        self.net_test_top_layer = self.net_test[layer_name]\n",
    "        \n",
    "    def l_fc(self, num_output):\n",
    "        if weight_filter is None:\n",
    "            weight_filter = self.weight_params\n",
    "        layer_name = 'dense' + str(self.fc_counter)\n",
    "        self.net_train[layer_name] = self.layers_creator.l_fc_create(self.net_train_top_layer, num_output, weight_filter)\n",
    "        self.net_test[layer_name] = self.layers_creator.l_fc_create(self.net_test_top_layer, num_output, weight_filter)\n",
    "        self.fc_counter += 1\n",
    "        \n",
    "        self.net_train_top_layer = self.net_train[layer_name]\n",
    "        self.net_test_top_layer = self.net_test[layer_name]\n",
    "\n",
    "    def l_score(self):\n",
    "        self.net_train['score'] = self.layers_creator.l_score_create(self.net_train_top_layer, num_output=self.count_of_classes, weight_filter=self.weight_params)\n",
    "        self.net_test['score'] = self.layers_creator.l_score_create(self.net_test_top_layer, num_output=self.count_of_classes, weight_filter=self.weight_params)\n",
    "        \n",
    "    def l_loss(self):\n",
    "        self.net_train['loss'] = self.layers_craetor.l_loss_create(self.net_train['score'], self.net_train['label'])\n",
    "        self.net_test['loss'] = self.layers_craetor.l_loss_create(self.net_train['score'], self.net_train['label'])\n",
    "        \n",
    "    def l_acc(self):\n",
    "        self.net_train['accuracy'] = self.layers_craetor.l_acc_create(self.net_train['score'], self.net_train['label'])\n",
    "        self.net_test['accuracy'] = self.layers_craetor.l_acc_create(self.net_train['score'], self.net_train['label'])\n",
    "        \n",
    "    def l_conv_batch_relu(self, kernel, filter_count, weight_filter=None, padding=1):\n",
    "        if weight_filter is None:\n",
    "            weight_filter = self.weight_params\n",
    "        self.l_conv(kernel, filter_count, weight_filter, padding)\n",
    "        self.l_batch()\n",
    "        self.l_relu()\n",
    "        \n",
    "    def l_conv_relu(self,  kernel, filter_count, weight_filter=None, padding=1):\n",
    "        if weight_filter is None:\n",
    "            weight_filter = self.weight_params\n",
    "        self.l_conv(kernel, filter_count, weight_filter, padding)\n",
    "        self.l_relu()\n",
    "        \n",
    "    def l_fc_relu(self, num_output, weight_filter=None):\n",
    "        if weight_filter is None:\n",
    "            weight_filter = self.weight_params\n",
    "        self.l_fc(num_output, weight_filter)\n",
    "        self.l_relu()\n",
    "        \n",
    "    def l_score_loss_acc(self):\n",
    "        self.l_score()\n",
    "        self.l_loss()\n",
    "        self.l_acc()\n",
    "        \n",
    "    def build(self):\n",
    "        train_name = os.path.join('proto',  self.name + '_train.prototxt') \n",
    "        test_name = os.path.join('proto',  self.name + '_test.prototxt') \n",
    "        \n",
    "        with open(train_name, 'w') as f:\n",
    "            f.write(str(self.net_train.to_proto()))\n",
    "\n",
    "        with open(test_name, 'w') as f:\n",
    "            f.write(str(self.net_test.to_proto()))\n",
    "            \n",
    "        self.conv_counter = 1\n",
    "        self.relu_counter = 1\n",
    "        self.pool_counter = 1\n",
    "        self.batch_counter = 1\n",
    "        self.fc_counter = 1\n",
    "        \n",
    "        print(\"Build was successfull\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaffeLayersCreator:\n",
    "    \n",
    "    def l_image_data_create(self, batch, _source, image_params):\n",
    "        return L.ImageData(\n",
    "            batch_size = batch,\n",
    "            source = _source,\n",
    "            is_color = image_params['is_color'],\n",
    "            new_height = image_params['new_height'],\n",
    "            new_width = image_params['new_width'],\n",
    "            shuffle = image_params['shuffle'],\n",
    "            ntop=2)\n",
    "    \n",
    "    def l_conv_create(self, top, kernel, filter_count, weight_filter, padding):\n",
    "        return L.Convolution(\n",
    "            top,\n",
    "            kernel_size=kernel,\n",
    "            pad=padding,\n",
    "            num_output=filter_count,\n",
    "            weight_filler=weight_filter\n",
    "        )\n",
    "    \n",
    "    def l_pool_create(self, top, kernel, shift, pool_strategy):\n",
    "        return L.Pooling(\n",
    "            top,\n",
    "            kernel_size=kernel,\n",
    "            stride=shift,\n",
    "            pool=pool_strategy\n",
    "        )\n",
    "        \n",
    "    def l_batch_create(self, top):\n",
    "        return L.BatchNorm(top)\n",
    "        \n",
    "    def l_relu_create(self, top, is_hidden):\n",
    "        return L.ReLU(top, is_hidden)\n",
    "        \n",
    "    def l_fc_create(self, top, weight_filter):\n",
    "        return L.InnerProduct(top, weight_filler=weight_filter)\n",
    "        \n",
    "    def l_score_create(self, top, weight_filter):\n",
    "        return l_fc_create(top, weight_filter)\n",
    "        \n",
    "    def l_loss_create(self, score, label):\n",
    "        return L.SoftmaxWithLoss(score, label)\n",
    "        \n",
    "    def l_acc_create(self, score, label):\n",
    "        return L.Accuracy(score, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"ImageData\"\n",
      "  top: \"data\"\n",
      "  top: \"label\"\n",
      "  image_data_param {\n",
      "    source: \"resources/train.txt\"\n",
      "    batch_size: 40\n",
      "    shuffle: true\n",
      "    new_height: 200\n",
      "    new_width: 200\n",
      "    is_color: false\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 32\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"batch1\"\n",
      "  type: \"BatchNorm\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"batch1\"\n",
      "}\n",
      "\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"ImageData\"\n",
      "  top: \"data\"\n",
      "  top: \"label\"\n",
      "  image_data_param {\n",
      "    source: \"resources/test.txt\"\n",
      "    batch_size: 40\n",
      "    shuffle: true\n",
      "    new_height: 200\n",
      "    new_width: 200\n",
      "    is_color: false\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 32\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"batch1\"\n",
      "  type: \"BatchNorm\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"batch1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ReLU input 1 is not a Top (type is <class 'bool'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f805932166c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_image_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_conv_batch_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_conv_batch_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-6047f541b088>\u001b[0m in \u001b[0;36ml_conv_batch_relu\u001b[0;34m(self, kernel, filter_count, weight_filter, padding)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_filter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0ml_conv_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-6047f541b088>\u001b[0m in \u001b[0;36ml_relu\u001b[0;34m(self, hidden)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mlayer_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_counter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_relu_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_train_top_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_relu_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_test_top_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-5c27ebd8fac0>\u001b[0m in \u001b[0;36ml_relu_create\u001b[0;34m(self, top, is_hidden)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0ml_relu_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0ml_fc_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_filter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/caffe/net_spec.py\u001b[0m in \u001b[0;36mlayer_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mlayer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mntop\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/caffe/net_spec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, type_name, inputs, params)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 raise TypeError('%s input %d is not a Top (type is %s)' %\n\u001b[0;32m--> 109\u001b[0;31m                                 (type_name, index, type(input)))\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ReLU input 1 is not a Top (type is <class 'bool'>)"
     ]
    }
   ],
   "source": [
    "net = CaffeNet('improved_vgg10')\n",
    "net.set_global_params(\n",
    "    batch_sizes=dict(train=40, test=40),\n",
    "    weight_params=dict(type='xavier'),\n",
    "    bias_params=dict(type='constant', value=0.1),\n",
    "    image_params=dict(train='resources/train.txt', test='resources/test.txt', is_color=False, new_height=200, new_width=200, shuffle=True),\n",
    "    count_of_classes=11)\n",
    "\n",
    "net.l_image_data()\n",
    "\n",
    "net.l_conv_batch_relu(3, 32)\n",
    "net.l_conv_batch_relu(3, 32)\n",
    "net.l_pool(2, 2)\n",
    "\n",
    "net.l_conv_batch_relu(3, 64)\n",
    "net.l_conv_batch_relu(3, 64)\n",
    "net.l_pool(2, 2)\n",
    "\n",
    "net.l_conv_batch_relu(3, 96)\n",
    "net.l_conv_batch_relu(3, 96)\n",
    "net.l_conv_batch_relu(3, 96)\n",
    "net.l_pool(2, 2)\n",
    "\n",
    "net.l_conv_batch_relu(3, 128)\n",
    "net.l_conv_batch_relu(3, 128)\n",
    "net.l_pool(2, 2)\n",
    "\n",
    "net.l_fc_relu(2000)\n",
    "net.l_fc_relu(1000)\n",
    "net.l_fc_relu(500)\n",
    "\n",
    "net.l_score_loss_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
